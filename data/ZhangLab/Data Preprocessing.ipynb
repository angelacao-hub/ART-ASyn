{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21895f59",
   "metadata": {},
   "source": [
    "# ZhangLab Chest X-ray Dataset Preprocessing Guide\n",
    "\n",
    "This notebook provides a comprehensive guide for downloading and preprocessing the ZhangLab chest X-ray dataset for ART-ASyn.\n",
    "\n",
    "## Dataset Information\n",
    "- **Source**: [ZhangLab Data Chest X-ray](https://datasetninja.com/zhang-lab-data-chest-xray)\n",
    "- **Type**: Chest X-ray images for medical diagnosis\n",
    "- **Format**: JPEG images\n",
    "- **Classes**: Normal (Healthy) vs. Diseased conditions\n",
    "\n",
    "## Overview\n",
    "The ZhangLab dataset contains chest X-ray images with binary classification:\n",
    "- **NORMAL**: Healthy chest X-rays\n",
    "- **ABNORMAL**: Diseased chest X-rays\n",
    "\n",
    "This preprocessing script organizes the data into a structured format suitable for machine learning models, separating training and testing sets with proper class organization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb66654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All required libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "print(\"‚úÖ All required libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "### Step 1: Download the Dataset\n",
    "\n",
    "Before running this notebook, you need to:\n",
    "\n",
    "1. **Visit the dataset source**: [ZhangLab Data Chest X-ray](https://datasetninja.com/zhang-lab-data-chest-xray)\n",
    "2. **Download the dataset** to your local machine\n",
    "   - **File Size**: 1.18GB\n",
    "   - **Downloaded File**: `zhanglabdata-chest-xray-DatasetNinja.tar`\n",
    "3. **Extract the dataset** to create the `../ZhangLabData` folder structure:\n",
    "   ```\n",
    "   ZhangLabData/           # Extract here\n",
    "   ‚îú‚îÄ‚îÄ train/\n",
    "   ‚îÇ   ‚îî‚îÄ‚îÄ img/\n",
    "   ‚îÇ       ‚îú‚îÄ‚îÄ NORMAL-0001-1.jpeg\n",
    "   ‚îÇ       ‚îú‚îÄ‚îÄ ABNORMAL-0001-2.jpeg\n",
    "   ‚îÇ       ‚îî‚îÄ‚îÄ ...\n",
    "   ‚îî‚îÄ‚îÄ test/\n",
    "       ‚îî‚îÄ‚îÄ img/\n",
    "           ‚îú‚îÄ‚îÄ NORMAL-0002-1.jpeg\n",
    "           ‚îî‚îÄ‚îÄ ...\n",
    "   ```\n",
    "\n",
    "**Note**: The main notebook directory should be at the same level as the `ZhangLabData` folder:\n",
    "```\n",
    "data/\n",
    "‚îú‚îÄ‚îÄ ZhangLab/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ Data Preprocessing.ipynb\n",
    "‚îî‚îÄ‚îÄ ZhangLabData/          # Dataset folder\n",
    "```\n",
    "\n",
    "### Step 2: Configure Data Paths\n",
    "\n",
    "Set the root directory where your ZhangLab dataset is located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d38e8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset directory found: ../ZhangLabData\n",
      "üìÅ Directory contents: [WindowsPath('../ZhangLabData/LICENSE.md'), WindowsPath('../ZhangLabData/meta.json'), WindowsPath('../ZhangLabData/README.md'), WindowsPath('../ZhangLabData/test'), WindowsPath('../ZhangLabData/train')]\n"
     ]
    }
   ],
   "source": [
    "# Configure dataset root directory\n",
    "# Change this path to match your local dataset location\n",
    "root = \"../ZhangLabData\"\n",
    "\n",
    "# Verify the dataset directory exists\n",
    "if Path(root).exists():\n",
    "    print(f\"‚úÖ Dataset directory found: {root}\")\n",
    "    print(f\"üìÅ Directory contents: {list(Path(root).iterdir())}\")\n",
    "else:\n",
    "    print(f\"‚ùå Dataset directory not found: {root}\")\n",
    "    print(\"Please ensure you have downloaded and extracted the dataset correctly.\")\n",
    "    print(\"Expected structure: ../ZhangLabData/{train,test}/{img/*.jpeg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing-section",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Overview\n",
    "\n",
    "The preprocessing pipeline will:\n",
    "1. **Organize images** by class (healthy vs diseased)\n",
    "2. **Create structured directories** for ML workflows\n",
    "3. **Separate training and testing** data\n",
    "4. **Ensure no duplicate processing** with existing files\n",
    "\n",
    "### Dataset Structure After Preprocessing\n",
    "\n",
    "```\n",
    "üìÇ ZhangLab/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ healthy/     # NORMAL class images\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ diseased/   # ABNORMAL class images\n",
    "‚îî‚îÄ‚îÄ test/\n",
    "    ‚îú‚îÄ‚îÄ healthy/     # NORMAL class images\n",
    "    ‚îî‚îÄ‚îÄ diseased/   # ABNORMAL class images\n",
    "```\n",
    "\n",
    "### File Naming Convention\n",
    "\n",
    "Original files follow the pattern: `{CLASS}-{STUDY}-{INDEX}.jpeg`\n",
    "- `CLASS`: NORMAL or ABNORMAL\n",
    "- `STUDY`: Study identifier number\n",
    "- `INDEX`: Image index within the study\n",
    "\n",
    "**Example**: `NORMAL-0001-1.jpeg` means:\n",
    "- Class: Normal (Healthy)\n",
    "- Study ID: 0001\n",
    "- Image index: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a7d572",
   "metadata": {},
   "source": [
    "## Training Data Preprocessing\n",
    "\n",
    "The following code processes the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0803d613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Processing training data...\n",
      "==================================================\n",
      "üìÅ Created directories: train\\healthy, train\\diseased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing training images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5232/5232 [00:00<00:00, 35020.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Training Data Processing Summary:\n",
      "   Total images processed: 0\n",
      "   Normal (Healthy) images: 1349\n",
      "   Abnormal (Diseased) images: 3883\n",
      "   Total original files: 5232\n",
      "‚úÖ Training data preprocessing completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process Training Data\n",
    "print(\"üîÑ Processing training data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create organized directory structure\n",
    "healthy_dir = Path(\"train/healthy\")\n",
    "diseased_dir = Path(\"train/diseased\")\n",
    "\n",
    "healthy_dir.mkdir(parents=True, exist_ok=True)\n",
    "diseased_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Created directories: {healthy_dir}, {diseased_dir}\")\n",
    "\n",
    "# Process each image file\n",
    "study_idx = []\n",
    "total_processed = 0\n",
    "normal_count = 0\n",
    "abnormal_count = 0\n",
    "\n",
    "for source in tqdm(list(Path(f\"{root}/train/img\").glob(\"*.jpeg\")), desc=\"Processing training images\"):\n",
    "    # Parse filename: CLASS-STUDY-INDEX.jpeg\n",
    "    status, study, idx = source.stem.split(\"-\")\n",
    "    \n",
    "    # Determine destination based on class\n",
    "    if status == \"NORMAL\":\n",
    "        destination = healthy_dir / source.parts[-1]\n",
    "        normal_count += 1\n",
    "    else:  # ABNORMAL\n",
    "        destination = diseased_dir / source.parts[-1]\n",
    "        abnormal_count += 1\n",
    "    \n",
    "    # Copy file if it doesn't already exist\n",
    "    if not destination.exists():\n",
    "        shutil.copy(source, destination)\n",
    "        total_processed += 1\n",
    "    \n",
    "    study_idx.append((status, study, idx))\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nüìä Training Data Processing Summary:\")\n",
    "print(f\"   Total images processed: {total_processed}\")\n",
    "print(f\"   Normal (Healthy) images: {normal_count}\")\n",
    "print(f\"   Abnormal (Diseased) images: {abnormal_count}\")\n",
    "print(f\"   Total original files: {normal_count + abnormal_count}\")\n",
    "\n",
    "print(\"‚úÖ Training data preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-processing",
   "metadata": {},
   "source": [
    "## Testing Data Preprocessing\n",
    "\n",
    "The following code processes the testing dataset using the same methodology as the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2599bc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Processing testing data...\n",
      "==================================================\n",
      "üìÅ Created directories: test\\healthy, test\\diseased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing testing images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 624/624 [00:00<00:00, 18546.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Testing Data Processing Summary:\n",
      "   Total images processed: 0\n",
      "   Normal (Healthy) images: 234\n",
      "   Abnormal (Diseased) images: 390\n",
      "   Total original files: 624\n",
      "‚úÖ Testing data preprocessing completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process Testing Data\n",
    "print(\"üîÑ Processing testing data...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create organized directory structure\n",
    "healthy_dir = Path(\"test/healthy\")\n",
    "diseased_dir = Path(\"test/diseased\")\n",
    "\n",
    "healthy_dir.mkdir(parents=True, exist_ok=True)\n",
    "diseased_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Created directories: {healthy_dir}, {diseased_dir}\")\n",
    "\n",
    "# Process each image file\n",
    "study_idx = []\n",
    "total_processed = 0\n",
    "normal_count = 0\n",
    "abnormal_count = 0\n",
    "\n",
    "for source in tqdm(list(Path(f\"{root}/test/img\").glob(\"*.jpeg\")), desc=\"Processing testing images\"):\n",
    "    # Parse filename: CLASS-STUDY-INDEX.jpeg\n",
    "    status, study, idx = source.stem.split(\"-\")\n",
    "    \n",
    "    # Determine destination based on class\n",
    "    if status == \"NORMAL\":\n",
    "        destination = healthy_dir / source.parts[-1]\n",
    "        normal_count += 1\n",
    "    else:  # ABNORMAL\n",
    "        destination = diseased_dir / source.parts[-1]\n",
    "        abnormal_count += 1\n",
    "    \n",
    "    # Copy file if it doesn't already exist\n",
    "    if not destination.exists():\n",
    "        shutil.copy(source, destination)\n",
    "        total_processed += 1\n",
    "    \n",
    "    study_idx.append((status, study, idx))\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nüìä Testing Data Processing Summary:\")\n",
    "print(f\"   Total images processed: {total_processed}\")\n",
    "print(f\"   Normal (Healthy) images: {normal_count}\")\n",
    "print(f\"   Abnormal (Diseased) images: {abnormal_count}\")\n",
    "print(f\"   Total original files: {normal_count + abnormal_count}\")\n",
    "\n",
    "print(\"‚úÖ Testing data preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-summary",
   "metadata": {},
   "source": [
    "## Final Dataset Summary\n",
    "\n",
    "Let's verify the final dataset structure and get a comprehensive summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "final-summary-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Final Dataset Summary\n",
      "============================================================\n",
      "üìÅ Dataset Structure:\n",
      "   Training - Healthy  :   1349 images\n",
      "   Training - Diseased :   3883 images\n",
      "   Testing - Healthy   :    234 images\n",
      "   Testing - Diseased  :    390 images\n",
      "------------------------------------------------------------\n",
      "Total Training      :   5232 images\n",
      "Total Testing       :    624 images\n",
      "Total Dataset       :   5856 images\n",
      "\n",
      "üìä Class Distribution:\n",
      "   Training Set:\n",
      "      Healthy  :   1349 (25.8%)\n",
      "      Diseased :   3883 (74.2%)\n",
      "   Testing Set:\n",
      "      Healthy  :    234 (37.5%)\n",
      "      Diseased :    390 (62.5%)\n",
      "\n",
      "‚úÖ Dataset preprocessing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Final Dataset Verification and Summary\n",
    "print(\"üìã Final Dataset Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def count_files(directory):\n",
    "    \"\"\"Count files in a directory\"\"\"\n",
    "    return len(list(Path(directory).glob(\"*\"))) if Path(directory).exists() else 0\n",
    "\n",
    "# Define dataset paths\n",
    "dataset_paths = {\n",
    "    \"Training - Healthy\": \"train/healthy\",\n",
    "    \"Training - Diseased\": \"train/diseased\", \n",
    "    \"Testing - Healthy\": \"test/healthy\",\n",
    "    \"Testing - Diseased\": \"test/diseased\"\n",
    "}\n",
    "\n",
    "# Count files and display summary\n",
    "total_train = 0\n",
    "total_test = 0\n",
    "\n",
    "print(\"üìÅ Dataset Structure:\")\n",
    "for label, path in dataset_paths.items():\n",
    "    count = count_files(path)\n",
    "    print(f\"   {label:<20}: {count:>6} images\")\n",
    "    \n",
    "    if \"Training\" in label:\n",
    "        total_train += count\n",
    "    else:\n",
    "        total_test += count\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Total Training':<20}: {total_train:>6} images\")\n",
    "print(f\"{'Total Testing':<20}: {total_test:>6} images\")\n",
    "print(f\"{'Total Dataset':<20}: {total_train + total_test:>6} images\")\n",
    "\n",
    "# Calculate class distribution\n",
    "train_healthy = count_files(\"train/healthy\")\n",
    "train_diseased = count_files(\"train/diseased\")\n",
    "test_healthy = count_files(\"test/healthy\")\n",
    "test_diseased = count_files(\"test/diseased\")\n",
    "\n",
    "print(\"\\nüìä Class Distribution:\")\n",
    "print(\"   Training Set:\")\n",
    "print(f\"      Healthy  : {train_healthy:>6} ({train_healthy/total_train*100:.1f}%)\")\n",
    "print(f\"      Diseased : {train_diseased:>6} ({train_diseased/total_train*100:.1f}%)\")\n",
    "print(\"   Testing Set:\")\n",
    "print(f\"      Healthy  : {test_healthy:>6} ({test_healthy/total_test*100:.1f}%)\")\n",
    "print(f\"      Diseased : {test_diseased:>6} ({test_diseased/total_test*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset preprocessing completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dist_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
